[{"categories":["技术"],"content":" kafka Stream实战 ","date":"2025-02-06","objectID":"/19/:0:0","tags":["高并发","编程"],"title":"kafka Stream实战","uri":"/19/"},{"categories":["技术"],"content":"1.要求 某车企通过将车辆传感器数据实时发送到服务器，再由 Kafka 作为数据总线接收这些数据,再调用第三方API 实现数据处理; 要求:QPS\u003e5w ","date":"2025-02-06","objectID":"/19/:1:0","tags":["高并发","编程"],"title":"kafka Stream实战","uri":"/19/"},{"categories":["技术"],"content":"2.实战 在 Kubernetes 集群上，我们部署了 Kafka Streams。最初的部署配置为 8 个 Pod，同时 Kafka Topic 的分区数设置为 36，此时系统的 QPS 达到约 7000+。为进一步提高并行处理能力和整体吞吐量，我们对 Kafka Topic 进行了优化，将分区数扩展到 102 个。经过调整后，系统的 QPS 显著提升至约 25,000+。但是还没达到5w 后续考虑 改回kafka consumer/producer + 异步消费的方式 ","date":"2025-02-06","objectID":"/19/:2:0","tags":["高并发","编程"],"title":"kafka Stream实战","uri":"/19/"},{"categories":["技术"],"content":" Netty个人理解 Netty 的事件驱动机制本质上是一种基于事件触发的异步编程模型。简单来说，它通过监听和触发事件的方式来处理网络通信中的各种操作，做到高效而灵活。 下面用一个生活中的例子来通俗解释： ","date":"2024-12-21","objectID":"/18/:0:0","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"1. 事件驱动的核心理念 想象你是一家快递公司的老板，负责安排快递员送快递。每天会有不同的客户来发快递，流程如下： 传统模型（阻塞式）： 每当一个客户到达，快递员要全程跟着客户，从拿包裹、贴标签、到送到目的地。只能一个一个服务，其他客户只能等待。 事件驱动模型（Netty 的方式）： 你设立了一个前台，客户到前台登记信息（一个事件），然后系统会根据情况通知空闲的快递员来接单。前台不需要等待某个快递完全送达再处理下一个客户。 ","date":"2024-12-21","objectID":"/18/:0:1","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"2. Netty 中的事件驱动 在 Netty 中，事件驱动机制是类似的： 事件产生： 网络数据的读写、连接建立、断开等行为被看作一个“事件”。 事件监听： Netty 提供 Channel 和 ChannelPipeline，这些组件类似于快递公司的前台，可以监听某些事件。 事件触发： 当有事件发生时（例如收到一个网络请求），Netty 会触发对应的事件，并分发到具体的处理器（ChannelHandler）进行处理。 ","date":"2024-12-21","objectID":"/18/:0:2","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"3. 关键组成部分（和快递的类比） Selector（选择器）：快递前台的排队窗口 Netty 使用 Selector 监控所有客户端的网络事件，例如“收到数据”或者“连接断开”。 快递前台并不会跟进每个包裹，而是快速处理登记，让事件进入系统。 Channel（通道）：每个快递员的送货任务 每个 Channel 表示一个与客户端的连接。 快递员负责把包裹（数据）运到目的地。 EventLoop（事件循环）：快递分配员 每个 EventLoop 负责处理一组 Channel 的事件，并将事件派发给对应的 ChannelHandler 处理。 类似一名分配员，分配任务给快递员，并持续循环处理所有到来的新任务。 ChannelPipeline（流水线）：快递过程中的处理流程 每个 Channel 都有一条 ChannelPipeline，其中包含一组 ChannelHandler，这些处理器按顺序处理网络事件。 类似快递包裹经过打包、分拣、运输等流程，层层加工后完成任务。 ","date":"2024-12-21","objectID":"/18/:0:3","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"4. Netty 的工作流程 假设一个客户端连接到 Netty 服务器，发生的事件驱动过程如下： 客户端连接（连接事件） 事件：ChannelActive 类似客户来前台登记一个快递。 EventLoop 接收到“新连接事件”，将其派发给 ChannelPipeline 进行处理。 发送数据（读事件） 事件：ChannelRead 客户端发送了一些数据，Netty 会监听这个数据并将它包装为事件。 数据被处理器（ChannelHandler）解析，例如检查、存储或转发。 断开连接（断开事件） 事件：ChannelInactive 客户端完成任务后断开连接，Netty 触发“断开连接事件”。 系统关闭资源，类似快递员完成任务后回到站点等待新的任务。 ","date":"2024-12-21","objectID":"/18/:0:4","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"5. 事件驱动的好处 高效： Netty 采用异步非阻塞的 IO 模型（NIO），一个线程可以处理多个连接的事件，提升资源利用率。 灵活： 不同类型的事件可以由不同的处理器处理，类似于不同的包裹走不同的物流流程。 简单： Netty 的事件驱动机制封装了底层的复杂操作，你只需要关心对事件的响应处理逻辑即可。 ","date":"2024-12-21","objectID":"/18/:0:5","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":"6. 简单总结 Netty 的事件驱动机制就像快递管理系统，所有的网络行为（如连接、读写、断开）都是事件，系统会自动分配任务给处理器完成，既快速又灵活。 它利用了异步非阻塞 IO，大幅提高了并发处理能力，非常适合高性能网络应用场景。 ","date":"2024-12-21","objectID":"/18/:0:6","tags":["netty","编程"],"title":"netty个人理解","uri":"/18/"},{"categories":["技术"],"content":" Kafka在分布式系统中的使用 在分布式系统中，Kafka Streams 的强大之处在于其能够高效地处理跨多个节点的数据流。下面我们来构建一个更复杂的 分布式流处理 场景，并以订单处理系统为例展示如何使用 Kafka Streams 实现分布式处理。 ","date":"2024-10-10","objectID":"/11/:0:0","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"场景描述 假设我们有一个电商系统，它分布式地处理用户的订单流。订单数据流不断涌入 Kafka 主题。我们希望在分布式环境下，能够实时处理这些订单，执行以下几步： 订单过滤：只处理金额大于 100 元的订单。 订单分类：根据订单的商品类型将订单分类。 统计处理：每 5 分钟内统计每种商品类型的订单数量，并进行实时更新。 结果输出：将统计结果输出到 Kafka 中的一个新的主题。 ","date":"2024-10-10","objectID":"/11/:0:1","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"分布式处理架构 该流处理任务将在多个实例上运行，每个实例可以处理一部分数据。Kafka Streams 的内部机制会确保数据被合理分配到各个实例上，实现分布式的无缝处理。 ","date":"2024-10-10","objectID":"/11/:0:2","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"1. Kafka Topics 订单输入主题 (orders)：包含所有用户下单的数据流，每条记录的值是订单信息。 { \"orderId\": \"12345\", \"productType\": \"electronics\", \"amount\": 150.0 } 订单统计输出主题 (order_statistics)：存储每个商品类型的实时订单统计信息。 { \"productType\": \"electronics\", \"count\": 50, \"windowStart\": \"2024-10-17T10:00:00\", \"windowEnd\": \"2024-10-17T10:05:00\" } ","date":"2024-10-10","objectID":"/11/:0:3","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"2. Kafka Streams 拓扑设计 流处理拓扑包含以下几个步骤： 读取 Kafka 订单主题。 过滤订单，只保留金额大于 100 元的订单。 根据商品类型进行分组。 基于 5 分钟的时间窗口进行统计。 将统计结果写回 Kafka 输出主题。 ","date":"2024-10-10","objectID":"/11/:0:4","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"3. 实现代码 以下是一个分布式订单处理系统的 Kafka Streams 代码示例： import org.apache.kafka.common.serialization.Serdes; import org.apache.kafka.streams.KafkaStreams; import org.apache.kafka.streams.StreamsBuilder; import org.apache.kafka.streams.StreamsConfig; import org.apache.kafka.streams.kstream.*; import org.apache.kafka.streams.state.Stores; import java.time.Duration; import java.util.Properties; public class DistributedOrderProcessing { public static void main(String[] args) { // Kafka Streams 配置 Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, \"order-processing-app\"); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\"); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass()); // 构建流处理拓扑 StreamsBuilder builder = new StreamsBuilder(); // 读取 \"orders\" 主题 KStream\u003cString, String\u003e orderStream = builder.stream(\"orders\"); // 过滤订单金额大于 100 的订单 KStream\u003cString, String\u003e filteredOrders = orderStream.filter((key, value) -\u003e { // 假设订单值是 JSON 字符串，将其解析为对象并判断金额 Order order = parseOrder(value); return order.getAmount() \u003e 100; }); // 按商品类型分组 KGroupedStream\u003cString, String\u003e groupedByProductType = filteredOrders.groupBy((key, value) -\u003e { Order order = parseOrder(value); return order.getProductType(); }); // 基于 5 分钟的窗口进行统计 TimeWindows timeWindows = TimeWindows.of(Duration.ofMinutes(5)); KTable\u003cWindowed\u003cString\u003e, Long\u003e productTypeCounts = groupedByProductType .windowedBy(timeWindows) .count(Materialized.as(Stores.persistentWindowStore(\"product-type-counts\", Duration.ofMinutes(5), Duration.ofMinutes(1), false))); // 将统计结果写入到 \"order_statistics\" 主题 productTypeCounts.toStream().map((key, value) -\u003e { String productType = key.key(); String windowStart = key.window().startTime().toString(); String windowEnd = key.window().endTime().toString(); return KeyValue.pair(productType, String.format(\"{\\\"productType\\\":\\\"%s\\\",\\\"count\\\":%d,\\\"windowStart\\\":\\\"%s\\\",\\\"windowEnd\\\":\\\"%s\\\"}\", productType, value, windowStart, windowEnd)); }).to(\"order_statistics\", Produced.with(Serdes.String(), Serdes.String())); // 创建 Kafka Streams 实例 KafkaStreams streams = new KafkaStreams(builder.build(), props); // 启动流处理应用 streams.start(); // 添加关闭 hook Runtime.getRuntime().addShutdownHook(new Thread(streams::close)); } // 解析订单数据（假设订单是 JSON 格式） private static Order parseOrder(String value) { // 此处省略具体的 JSON 解析逻辑 // 返回一个 Order 对象 return new Order(\"12345\", \"electronics\", 150.0); } // 模拟订单类 static class Order { private String orderId; private String productType; private double amount; public Order(String orderId, String productType, double amount) { this.orderId = orderId; this.productType = productType; this.amount = amount; } public String getOrderId() { return orderId; } public String getProductType() { return productType; } public double getAmount() { return amount; } } } ","date":"2024-10-10","objectID":"/11/:0:5","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"4. 分布式处理 在这个示例中，Kafka Streams 的分布式特性能够自动将处理任务分布到不同的实例上。当我们在多个机器或多个 JVM 实例上运行这个应用时，Kafka Streams 会自动： 分配分区：根据 Kafka 主题分区将不同的分区数据分配给不同的实例处理。 故障恢复：如果某个实例失败，Kafka Streams 会自动将失败实例的任务重新分配给其他活跃的实例。 状态存储：对于有状态的操作（如 count()），Kafka Streams 使用内部的存储机制（如 RocksDB）来保持处理状态，这些状态也可以被持久化到 Kafka 中，以便在故障时恢复。 ","date":"2024-10-10","objectID":"/11/:0:6","tags":["分布式","编程"],"title":"kafka在分布式系统中的使用","uri":"/11/"},{"categories":["技术"],"content":"1. 图形用户界面（GUI）组件 场景：创建不同操作系统的 GUI 组件，如按钮和文本框。 应用 interface Button { void paint(); } interface TextBox { void display(); } interface GUIFactory { Button createButton(); TextBox createTextBox(); } class WindowsButton implements Button { public void paint() { System.out.println(\"Windows Button\"); } } class WindowsTextBox implements TextBox { public void display() { System.out.println(\"Windows TextBox\"); } } class MacButton implements Button { public void paint() { System.out.println(\"Mac Button\"); } } class MacTextBox implements TextBox { public void display() { System.out.println(\"Mac TextBox\"); } } class WindowsFactory implements GUIFactory { public Button createButton() { return new WindowsButton(); } public TextBox createTextBox() { return new WindowsTextBox(); } } class MacFactory implements GUIFactory { public Button createButton() { return new MacButton(); } public TextBox createTextBox() { return new MacTextBox(); } } // 使用 GUIFactory factory = new WindowsFactory(); Button button = factory.createButton(); TextBox textBox = factory.createTextBox(); button.paint(); textBox.display(); ","date":"2024-05-22","objectID":"/17/:0:1","tags":["设计模型","编程"],"title":"抽象工厂模式的具体实现","uri":"/17/"},{"categories":["技术"],"content":"2. 数据库连接 场景：支持多种数据库（如 MySQL 和 PostgreSQL）。 应用 ： java interface Connection { void connect(); } interface Command { void execute(); } interface DatabaseFactory { Connection createConnection(); Command createCommand(); } class MySQLConnection implements Connection { public void connect() { System.out.println(\"Connected to MySQL\"); } } class MySQLCommand implements Command { public void execute() { System.out.println(\"Executing MySQL command\"); } } class PostgreSQLConnection implements Connection { public void connect() { System.out.println(\"Connected to PostgreSQL\"); } } class PostgreSQLCommand implements Command { public void execute() { System.out.println(\"Executing PostgreSQL command\"); } } class MySQLFactory implements DatabaseFactory { public Connection createConnection() { return new MySQLConnection(); } public Command createCommand() { return new MySQLCommand(); } } class PostgreSQLFactory implements DatabaseFactory { public Connection createConnection() { return new PostgreSQLConnection(); } public Command createCommand() { return new PostgreSQLCommand(); } } // 使用 DatabaseFactory factory = new MySQLFactory(); Connection connection = factory.createConnection(); Command command = factory.createCommand(); connection.connect(); command.execute(); ","date":"2024-05-22","objectID":"/17/:0:2","tags":["设计模型","编程"],"title":"抽象工厂模式的具体实现","uri":"/17/"},{"categories":["技术"],"content":"3. 汽车制造 场景：制造不同类型的汽车（如 SUV 和轿车）。 应用 ： java interface Engine { void start(); } interface Tire { void roll(); } interface CarFactory { Engine createEngine(); Tire createTire(); } class SUVEngine implements Engine { public void start() { System.out.println(\"Starting SUV engine\"); } } class SUVTire implements Tire { public void roll() { System.out.println(\"Rolling SUV tire\"); } } class SedanEngine implements Engine { public void start() { System.out.println(\"Starting Sedan engine\"); } } class SedanTire implements Tire { public void roll() { System.out.println(\"Rolling Sedan tire\"); } } class SUVFactory implements CarFactory { public Engine createEngine() { return new SUVEngine(); } public Tire createTire() { return new SUVTire(); } } class SedanFactory implements CarFactory { public Engine createEngine() { return new SedanEngine(); } public Tire createTire() { return new SedanTire(); } } // 使用 CarFactory factory = new SUVFactory(); Engine engine = factory.createEngine(); Tire tire = factory.createTire(); engine.start(); tire.roll(); ","date":"2024-05-22","objectID":"/17/:0:3","tags":["设计模型","编程"],"title":"抽象工厂模式的具体实现","uri":"/17/"},{"categories":["技术"],"content":"4. 报告生成 场景：生成不同格式的报告（如 PDF 和 Word）。 应用 ： java interface Report { void generate(); } interface ReportFactory { Report createReport(); } class PDFReport implements Report { public void generate() { System.out.println(\"Generating PDF report\"); } } class WordReport implements Report { public void generate() { System.out.println(\"Generating Word report\"); } } class PDFReportFactory implements ReportFactory { public Report createReport() { return new PDFReport(); } } class WordReportFactory implements ReportFactory { public Report createReport() { return new WordReport(); } } // 使用 ReportFactory factory = new PDFReportFactory(); Report report = factory.createReport(); report.generate(); ","date":"2024-05-22","objectID":"/17/:0:4","tags":["设计模型","编程"],"title":"抽象工厂模式的具体实现","uri":"/17/"},{"categories":["技术"],"content":" 设计模型具体实现 ","date":"2024-05-21","objectID":"/16/:0:0","tags":["设计模型","编程"],"title":"策略模式的具体实现","uri":"/16/"},{"categories":["技术"],"content":"1. 支付方式选择 场景：在电商应用中，用户可以选择不同的支付方式（如信用卡、PayPal、比特币）。 实现 // 策略接口 interface PaymentStrategy { void pay(int amount); } // 具体策略：信用卡支付 class CreditCardPayment implements PaymentStrategy { public void pay(int amount) { System.out.println(\"Paid \" + amount + \" using Credit Card.\"); } } // 具体策略：PayPal支付 class PayPalPayment implements PaymentStrategy { public void pay(int amount) { System.out.println(\"Paid \" + amount + \" using PayPal.\"); } } // 上下文 class ShoppingCart { private PaymentStrategy paymentStrategy; public void setPaymentStrategy(PaymentStrategy paymentStrategy) { this.paymentStrategy = paymentStrategy; } public void checkout(int amount) { paymentStrategy.pay(amount); } } 使用示例 java public class Main { public static void main(String[] args) { ShoppingCart cart = new ShoppingCart(); cart.setPaymentStrategy(new CreditCardPayment()); cart.checkout(100); cart.setPaymentStrategy(new PayPalPayment()); cart.checkout(200); } } ","date":"2024-05-21","objectID":"/16/:0:1","tags":["设计模型","编程"],"title":"策略模式的具体实现","uri":"/16/"},{"categories":["技术"],"content":"2. 排序算法选择 场景：在应用中，用户可以选择不同的排序算法（如快速排序、冒泡排序）。 实现 java // 策略接口 interface SortStrategy { void sort(int[] array); } // 具体策略：快速排序 class QuickSort implements SortStrategy { public void sort(int[] array) { // 快速排序实现 System.out.println(\"QuickSort applied.\"); } } // 具体策略：冒泡排序 class BubbleSort implements SortStrategy { public void sort(int[] array) { // 冒泡排序实现 System.out.println(\"BubbleSort applied.\"); } } // 上下文 class SortContext { private SortStrategy sortStrategy; public void setSortStrategy(SortStrategy sortStrategy) { this.sortStrategy = sortStrategy; } public void sortArray(int[] array) { sortStrategy.sort(array); } } 使用示例 java public class Main { public static void main(String[] args) { SortContext context = new SortContext(); int[] array = {5, 3, 8, 1}; context.setSortStrategy(new QuickSort()); context.sortArray(array); context.setSortStrategy(new BubbleSort()); context.sortArray(array); } } ","date":"2024-05-21","objectID":"/16/:0:2","tags":["设计模型","编程"],"title":"策略模式的具体实现","uri":"/16/"},{"categories":["技术"],"content":"3. 文件压缩工具 场景：用户可以选择不同的文件压缩算法（如 ZIP、RAR）。 实现 java // 策略接口 interface CompressionStrategy { void compress(String fileName); } // 具体策略：ZIP压缩 class ZipCompression implements CompressionStrategy { public void compress(String fileName) { System.out.println(\"Compressing \" + fileName + \" using ZIP.\"); } } // 具体策略：RAR压缩 class RarCompression implements CompressionStrategy { public void compress(String fileName) { System.out.println(\"Compressing \" + fileName + \" using RAR.\"); } } // 上下文 class CompressionContext { private CompressionStrategy compressionStrategy; public void setCompressionStrategy(CompressionStrategy compressionStrategy) { this.compressionStrategy = compressionStrategy; } public void compressFile(String fileName) { compressionStrategy.compress(fileName); } } 使用示例 java public class Main { public static void main(String[] args) { CompressionContext context = new CompressionContext(); context.setCompressionStrategy(new ZipCompression()); context.compressFile(\"file1.txt\"); context.setCompressionStrategy(new RarCompression()); context.compressFile(\"file2.txt\"); } } ","date":"2024-05-21","objectID":"/16/:0:3","tags":["设计模型","编程"],"title":"策略模式的具体实现","uri":"/16/"},{"categories":["技术"],"content":"4. 旅行路径选择 场景：用户选择不同的旅行策略（如驾车、步行、骑行）。 实现 java // 策略接口 interface TravelStrategy { void travel(String start, String destination); } // 具体策略：驾车 class CarTravel implements TravelStrategy { public void travel(String start, String destination) { System.out.println(\"Traveling by car from \" + start + \" to \" + destination); } } // 具体策略：步行 class WalkingTravel implements TravelStrategy { public void travel(String start, String destination) { System.out.println(\"Walking from \" + start + \" to \" + destination); } } // 上下文 class TravelContext { private TravelStrategy travelStrategy; public void setTravelStrategy(TravelStrategy travelStrategy) { this.travelStrategy = travelStrategy; } public void travel(String start, String destination) { travelStrategy.travel(start, destination); } } 使用示例 java public class Main { public static void main(String[] args) { TravelContext context = new TravelContext(); context.setTravelStrategy(new CarTravel()); context.travel(\"Home\", \"Office\"); context.setTravelStrategy(new WalkingTravel()); context.travel(\"Home\", \"Park\"); } } ","date":"2024-05-21","objectID":"/16/:0:4","tags":["设计模型","编程"],"title":"策略模式的具体实现","uri":"/16/"},{"categories":["生活"],"content":" 王府井 ","date":"2024-01-18","objectID":"/14/:0:0","tags":["北京","王府井"],"title":"王府井","uri":"/14/"},{"categories":["生活"],"content":" 王府井 ","date":"2024-01-03","objectID":"/15/:0:0","tags":["北京","下班"],"title":"下班途中","uri":"/15/"},{"categories":["技术"],"content":" 自学响应式编程(一) ","date":"2024-01-01","objectID":"/13/:0:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/13/"},{"categories":["技术"],"content":"1、Lambda package com.atguiggu.lambda; import java.util.*; import java.util.function.*; import java.util.stream.Collectors; /** * @author lfy * @Description * @create 2023-11-16 20:07 */ //函数式接口；只要是函数式接口就可以用Lambda表达式简化 //函数式接口： 接口中有且只有一个未实现的方法，这个接口就叫函数式接口 interface MyInterface { int sum(int i, int j); } interface MyHaha { int haha(); default int heihei() { return 2; } ; //默认实现 } interface My666 { void aaa(int i,int j,int k); } @FunctionalInterface //检查注解，帮我们快速检查我们写的接口是否函数式接口 interface MyHehe { int hehe(int i); } //1、自己写实现类 class MyInterfaceImpl implements MyInterface { @Override public int sum(int i, int j) { return i + j; } } public class Lambda { public static void main(String[] args) { //声明一个函数 BiConsumer\u003cString,String\u003e consumer = (a,b)-\u003e{ System.out.println(\"哈哈：\"+a+\"；呵呵：\"+b); }; consumer.accept(\"1\",\"2\"); //声明一个函数 Function\u003cString,Integer\u003e function = (String x) -\u003e Integer.parseInt(x); System.out.println(function.apply(\"2\")); Supplier\u003cString\u003e supplier = ()-\u003e UUID.randomUUID().toString(); String s = supplier.get(); System.out.println(s); BiFunction\u003cString,Integer,Long\u003e biFunction = (a,b)-\u003e 888L; Predicate\u003cInteger\u003e even = (t)-\u003e t%2 ==0; // even.test()//正向判断 // even.negate().test(2) //反向判断 System.out.println(even.negate().test(2)); } public static void bbbbb(String[] args) { var names = new ArrayList\u003cString\u003e(); names.add(\"Alice\"); names.add(\"Bob\"); names.add(\"Charlie\"); names.add(\"David\"); //比较器 // Collections.sort(names, new Comparator\u003cString\u003e() { // @Override // public int compare(String o1, String o2) { // return o2.compareTo(o1); // } // }); //直接写函数式接口就方便 (o1,o2)-\u003eo1.compareTo(o2) // Collections.sort(names,(o1,o2)-\u003eo1.compareTo(o2)); System.out.println(names); // 类::方法； 引用类中的实例方法； 忽略lambda的完整写法 Collections.sort(names,String::compareTo); System.out.println(names); new Thread( new Runnable() { @Override public void run() { System.out.println(\"哈哈啊\"); } } ).start(); Runnable runnable = () -\u003e System.out.println(\"aaa\"); new Thread(runnable).start(); //最佳实战： //1、以后调用某个方法传入参数，这个参数实例是一个接口对象，且只定义了一个方法，就直接用lambda简化写法 } /** * lambda简化函数式接口实例创建 * * @param args */ public static void aaaa(String[] args) { //1、自己创建实现类对象 MyInterface myInterface = new MyInterfaceImpl(); System.out.println(myInterface.sum(1, 2)); //2、创建匿名实现类 MyInterface myInterface1 = new MyInterface() { @Override public int sum(int i, int j) { return i * i + j * j; } }; // System.out.println(myInterface1.sum(2, 3)); //冗余写法 //3、lambda表达式:语法糖 参数列表 + 箭头 + 方法体 MyInterface myInterface2 = (x, y) -\u003e { return x * x + y * y; }; System.out.println(myInterface2.sum(2, 3)); //参数位置最少情况 MyHaha myHaha = () -\u003e { return 1; }; MyHehe myHehe = y -\u003e { return y * y; }; MyHehe hehe2 = y -\u003e y - 1; //完整写法如上： //简化写法： //1)、参数类型可以不写，只写(参数名)，参数变量名随意定义; // 参数表最少可以只有一个 ()，或者只有一个参数名； //2、方法体如果只有一句话，{} 可以省略 MyHehe hehe3 = y -\u003e y + 1; System.out.println(hehe3.hehe(7)); //以上Lambda表达式简化了实例的创建。 //总结： // 1、Lambda表达式： (参数表) -\u003e {方法体} // 2、分辨出你的接口是否函数式接口。 函数式接口就可以lambda简化 } } ","date":"2024-01-01","objectID":"/13/:1:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/13/"},{"categories":["技术"],"content":"2、Function 1、有入参，无出参【消费者】： function.accept BiConsumer\u003cString,String\u003e function = (a,b)-\u003e{ //能接受两个入参 System.out.println(\"哈哈：\"+a+\"；呵呵：\"+b); }; function.accept(\"1\",\"2\"); 2、有入参，有出参【多功能函数】： function.apply Function\u003cString,Integer\u003e function = (String x) -\u003e Integer.parseInt(x); System.out.println(function.apply(\"2\")); 3、无入参，无出参【普通函数】： Runnable runnable = () -\u003e System.out.println(\"aaa\"); new Thread(runnable).start(); 4、无入参 ，有出参【提供者】： supplier.get() Supplier\u003cString\u003e supplier = ()-\u003e UUID.randomUUID().toString(); String s = supplier.get(); System.out.println(s); java.util.function包下的所有function定义： Consumer： 消费者 Supplier： 提供者 Predicate： 断言 get/test/apply/accept调用的函数方法； ","date":"2024-01-01","objectID":"/13/:2:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/13/"},{"categories":["技术"],"content":"3、StreamAPI 最佳实战：以后凡是你写for循环处理数据的统一全部用StreamAPI进行替换； Stream所有数据和操作被组合成流管道流管道组成： 一个数据源（可以是一个数组、集合、生成器函数、I/O管道） 零或多个中间操作（将一个流变形成另一个流） 一个终止操作（产生最终结果） ","date":"2024-01-01","objectID":"/13/:3:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/13/"},{"categories":["技术"],"content":"中间操作：Intermediate Operations filter：过滤； 挑出我们用的元素 map： 映射： 一一映射，a 变成 b mapToInt、mapToLong、mapToDouble flatMap：打散、散列、展开、扩维：一对多映射 filter、 map、mapToInt、mapToLong、mapToDouble flatMap、flatMapToInt、flatMapToLong、flatMapToDouble mapMulti、mapMultiToInt、mapMultiToLong、mapMultiToDouble、 parallel、unordered、onClose、sequential distinct、sorted、peek、limit、skip、takeWhile、dropWhile、 forEach、forEachOrdered、toArray、reduce、collect、toList、min、 max、count、anyMatch、allMatch、noneMatch、findFirst、findAny、iterator ","date":"2024-01-01","objectID":"/13/:3:1","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/13/"},{"categories":["技术"],"content":" 代码优化之去掉if else ","date":"2023-12-20","objectID":"/10/:0:0","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["技术"],"content":"方式一 - 工厂类 定义一个操作接口 public interface Operation { int apply(int a, int b); } 实现操作， 这里只以add为例 public class Addition implements Operation { @Override public int apply(int a, int b) { return a + b; } } 实现操作工厂 public class OperatorFactory { static Map\u003cString, Operation\u003e operationMap = new HashMap\u003c\u003e(); static { operationMap.put(\"add\", new Addition()); operationMap.put(\"divide\", new Division()); // more operators } public static Optional\u003cOperation\u003e getOperation(String operator) { return Optional.ofNullable(operationMap.get(operator)); } } 在Calculator中调用 public int calculateUsingFactory(int a, int b, String operator) { Operation targetOperation = OperatorFactory .getOperation(operator) .orElseThrow(() -\u003e new IllegalArgumentException(\"Invalid Operator\")); return targetOperation.apply(a, b); } Java 8 - 函数编程(lambda表达式) Lambda 表达式的特点? Lambda 表达式使用和Stream下的接口? 函数接口定义和使用，四大内置函数接口Consumer，Function，Supplier, Predicate. Comparator排序为例贯穿所有知识点。 Java 8 - Optional类深度解析 Optional类的意义? Optional类有哪些常用的方法? Optional举例贯穿所有知识点 如何解决多重类嵌套Null值判断? ","date":"2023-12-20","objectID":"/10/:0:1","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["技术"],"content":"方式二 - 枚举 枚举适合类型固定，可枚举的情况，比如这的操作符; 同时枚举中是可以提供方法实现的，这就是我们可以通过枚举进行重构的原因。 定义操作符枚举 public enum Operator { ADD { @Override public int apply(int a, int b) { return a + b; } }, // other operators public abstract int apply(int a, int b); } 在Calculator中调用 public int calculate(int a, int b, Operator operator) { return operator.apply(a, b); } 写个测试用例测试下： @Test public void whenCalculateUsingEnumOperator_thenReturnCorrectResult() { Calculator calculator = new Calculator(); int result = calculator.calculate(3, 4, Operator.valueOf(\"ADD\")); assertEquals(7, result); } 看是否很简单? ","date":"2023-12-20","objectID":"/10/:0:2","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["技术"],"content":"方法三 - 命令模式 命令模式也是非常常用的重构方式， 把每个操作符当作一个Command。 首先让我们回顾下什么是命令模式 命令模式(Command pattern): 将\"请求\"封闭成对象, 以便使用不同的请求,队列或者日志来参数化其他对象. 命令模式也支持可撤销的操作。 Command: 命令 Receiver: 命令接收者，也就是命令真正的执行者 Invoker: 通过它来调用命令 Client: 可以设置命令与命令的接收者 Command接口 public interface Command { Integer execute(); } 实现Command public class AddCommand implements Command { // Instance variables public AddCommand(int a, int b) { this.a = a; this.b = b; } @Override public Integer execute() { return a + b; } } 在Calculator中调用 public int calculate(Command command) { return command.execute(); } 测试用例 @Test public void whenCalculateUsingCommand_thenReturnCorrectResult() { Calculator calculator = new Calculator(); int result = calculator.calculate(new AddCommand(3, 7)); assertEquals(10, result); } 注意，这里new AddCommand(3, 7)仍然没有解决动态获取操作符问题，所以通常来说可以结合简单工厂模式来调用： 创建型 - 简单工厂(Simple Factory) 简单工厂(Simple Factory)，它把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化，这样做能把客户类和具体子类的实现解耦，客户类不再需要知道有哪些子类以及应当实例化哪个子类 ","date":"2023-12-20","objectID":"/10/:0:3","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["技术"],"content":"方法四 - 规则引擎 规则引擎适合规则很多且可能动态变化的情况，在先要搞清楚一点Java OOP，即类的抽象： 这里可以抽象出哪些类？// 头脑中需要有这种自动转化 规则Rule 规则接口 具体规则的泛化实现 表达式Expression 操作符 操作数 规则引擎 定义规则 public interface Rule { boolean evaluate(Expression expression); Result getResult(); } Add 规则 public class AddRule implements Rule { @Override public boolean evaluate(Expression expression) { boolean evalResult = false; if (expression.getOperator() == Operator.ADD) { this.result = expression.getX() + expression.getY(); evalResult = true; } return evalResult; } } 表达式 public class Expression { private Integer x; private Integer y; private Operator operator; } 规则引擎 public class RuleEngine { private static List\u003cRule\u003e rules = new ArrayList\u003c\u003e(); static { rules.add(new AddRule()); } public Result process(Expression expression) { Rule rule = rules .stream() .filter(r -\u003e r.evaluate(expression)) .findFirst() .orElseThrow(() -\u003e new IllegalArgumentException(\"Expression does not matches any Rule\")); return rule.getResult(); } } 测试用例 @Test public void whenNumbersGivenToRuleEngine_thenReturnCorrectResult() { Expression expression = new Expression(5, 5, Operator.ADD); RuleEngine engine = new RuleEngine(); Result result = engine.process(expression); assertNotNull(result); assertEquals(10, result.getValue()); } ","date":"2023-12-20","objectID":"/10/:0:4","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["技术"],"content":"方法五 - 策略模式 策略模式比命令模式更为常用，而且在实际业务逻辑开发中需要注入一定的（比如通过Spring的@Autowired来注入bean），这时通过策略模式可以巧妙的重构 什么是策略模式？ 策略模式(strategy pattern): 定义了算法族, 分别封闭起来, 让它们之间可以互相替换, 此模式让算法的变化独立于使用算法的客户 Strategy 接口定义了一个算法族，它们都具有 behavior() 方法。 Context 是使用到该算法族的类，其中的 doSomething() 方法会调用 behavior()，setStrategy(in Strategy) 方法可以动态地改变 strategy 对象，也就是说能动态地改变 Context 所使用的算法。 Spring中需要注入资源重构？ 如果是在实现业务逻辑需要注入框架中资源呢？比如通过Spring的@Autowired来注入bean。可以这样实现： 操作 public interface Opt { int apply(int a, int b); } @Component(value = \"addOpt\") public class AddOpt implements Opt { @Autowired xxxAddResource resource; // 这里通过Spring框架注入了资源 @Override public int apply(int a, int b) { return resource.process(a, b); } } @Component(value = \"devideOpt\") public class devideOpt implements Opt { @Autowired xxxDivResource resource; // 这里通过Spring框架注入了资源 @Override public int apply(int a, int b) { return resource.process(a, b); } } 策略 @Component public class OptStrategyContext{ private Map\u003cString, Opt\u003e strategyMap = new ConcurrentHashMap\u003c\u003e(); @Autowired public OptStrategyContext(Map\u003cString, TalkService\u003e strategyMap) { this.strategyMap.clear(); this.strategyMap.putAll(strategyMap); } public int apply(Sting opt, int a, int b) { return strategyMap.get(opt).apply(a, b); } } 上述代码在实现中非常常见。 ","date":"2023-12-20","objectID":"/10/:0:5","tags":["if","code"],"title":"代码优化之去掉if else","uri":"/10/"},{"categories":["生活"],"content":" 功能测试文章 ","date":"2023-11-30","objectID":"/12/:0:0","tags":["北京","什刹海"],"title":"傍晚的什刹海","uri":"/12/"},{"categories":["生活"],"content":" 北京老街 ","date":"2023-11-29","objectID":"/8/:0:0","tags":["拍照","旅游"],"title":"北京老街","uri":"/8/"},{"categories":["生活"],"content":" 地铁站 ","date":"2023-11-28","objectID":"/5/:0:0","tags":["拍照"],"title":"杂拍","uri":"/5/"},{"categories":["文章"],"content":" 转载自4'000 Stars and counting, a trip down memory lane 我很幸运能够在 2014 年成为第一批踏上 Docker 之旅的人之一，尝试将监控堆栈容器化。我在 2014 年初开始了解 Docker，并花了几个月的时间弄清楚它是如何工作的以及在工程师的 DM 中修复错误并提出大量问题。此时只有少数人在聊天，而且社区很小，我们认识每个人。 作为一名监控和数据极客，我的任务是在 2014 年为我们的新云企业构建适应性更强的监控解决方案。最初，我尝试在 Nagios 等 Docker 容器中重建当前的监控解决方案，然后才对容器友好。 、Centreon、Piwik 分析和许多其他工具并没有真正解决我的问题。我偶然发现 InfluxDB 和 Grafana，但很快意识到它不符合我们的用例。 经过对不同工具的多次尝试和错误后，我偶然发现了 Soundcloud 基础设施博客以及他们如何使用微服务架构构建用 Go 编写的时间序列监控工具。在当时，这似乎太过超前和牵强，甚至显得不真实。如果我没记错的话，这是一篇向公众推出 Prometheus 的博客文章 - https://developers.soundcloud.com/blog/prometheus-monitoring-at-soundcloud 首先是将所有东西容器化。 不管你信不信，回到 2014 年，那是一个没有编曲家的时代。大多数人将一堆单个 Docker 运行命令与 bash 脚本串在一起，并尝试使用 bash 来“编排”容器。 幸运的是，2015 年，一家名为 Orchard 的公司正忙于构建第一个名为“ *fig”的 Docker 容器编排器。*Fig 绝对是一个了不起的工具。你可以编写一些奇怪的代码，称为 YAML，这是我之前从未见过的，基本上，将所有 Docker 运行命令串到一个文件中，允许你将微服务构建到一个文件中…… Docker 运行命令的单个文件 == 令人震惊 在我开始使用Fig并加快速度后不久，Docker宣布他们已经收购了母公司Orchard。您还可以在 Docker Compose 版本历史记录中看到Fig 于 2014 年 10 月加入 Docker时的精彩历史快照。 几个月后，Docker 在 2015 年 2 月将 Fig 更名为 Docker Compose，这是容器历史上我永远不会忘记的里程碑。之后，我开始研究如何将我最喜欢的所有监控工具放入一个撰写文件中。我开始使用 Prometheus、Grafana、Node Exporters 和 Google cAdvisor。我花了几周的时间才弄清楚 compose 内部的网络，因为这还处于早期阶段，我们今天认为理所当然的很多东西还没有实现。让容器通过多个服务相互通信、配置、安装存储等是一项任务，但它确实有效。 下面您可以看到我使用 Prometheus 和 Grafana 创建的第一个仪表板。它并不漂亮，但是嘿，它在 Docker Compose 中协同工作，而且还监视容器和基础设施。 Prometheus 和 Grafana 仪表板的第一个版本 在它启动并运行之后，我在博客上写了几次关于它的文章，它获得了 Docker、Google 和整个社区的大量关注。谷歌实际上主动联系我，要求我在他们位于瑞士苏黎世的总部展示我正在开发的产品。 我不知道我是否是第一个使用 Docker 和 Compose 创建完整监控堆栈的人，但我绝对是第一个创建详细手册、简单的一键部署指南、Docker 监控研讨会并点击会议巡回培训 100 名人员如何开始使用 Docker 和监控。很快就成为第一批 Docker 队长之一，写书，参加采访，并很早就成为 Docker 社区不可或缺的一部分。 Docker Prometheus 项目的目标是帮助他人并回馈社区，这对我来说始终很重要。开源不仅对于编写代码非常重要，而且对于支持、教导和指导他人也非常重要。我相信这个项目帮助启动了其他一些项目和组织，以继续构建令人惊叹的事物。 接下来我知道，Docker Prometheus GitHub 项目的启动次数为 1k，然后是 2k，现在是 4k。GitHub 的星星曾经有较早的含义；一些公司甚至使用 GitHub star 的数量作为向 VC 推销的指标。现在，这只是一个虚荣指标，但我仍然喜欢偶尔检查和反思。 这是一段令人惊奇的旅程，但距离完成还很遥远。我鼓励每个人尽其所能帮助回馈开源，从编写代码到修复文档。每一项贡献都有帮助 ","date":"2023-11-21","objectID":"/6/:0:0","tags":["docker"],"title":"docker-compose怎么来的","uri":"/6/"},{"categories":["技术"],"content":"远程 Debug 配置 IDEA中添加Remote JVM Debug配置项，拷贝以下配置 -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005 ","date":"2023-11-21","objectID":"/1/:1:0","tags":["IDEA","Docker"],"title":"IDEA远程调试docker容器","uri":"/1/"},{"categories":["技术"],"content":"容器启动配置 ","date":"2023-11-21","objectID":"/1/:2:0","tags":["IDEA","Docker"],"title":"IDEA远程调试docker容器","uri":"/1/"},{"categories":["技术"],"content":"dockerfile配置 FROM openjdk:8 ADD ./myapp.jar ./ EXPOSE 8082 EXPOSE 5005 ENTRYPOINT [\"java\",\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005\",\"-jar\",\"myapp.jar\",\"--spring.profiles.active=prod\"] ","date":"2023-11-21","objectID":"/1/:2:1","tags":["IDEA","Docker"],"title":"IDEA远程调试docker容器","uri":"/1/"},{"categories":["技术"],"content":"docker-compose配置 暴露debug端口 Server: image: server container_name: server ports: - \"30010:8082\" - \"5005:5005\" ","date":"2023-11-21","objectID":"/1/:2:2","tags":["IDEA","Docker"],"title":"IDEA远程调试docker容器","uri":"/1/"},{"categories":["技术"],"content":"配置debug调试 ","date":"2023-11-21","objectID":"/1/:2:3","tags":["IDEA","Docker"],"title":"IDEA远程调试docker容器","uri":"/1/"},{"categories":["生活"],"content":" 北京温榆河 ","date":"2023-11-21","objectID":"/9/:0:0","tags":["拍照","温榆河"],"title":"北京温榆河","uri":"/9/"},{"categories":["搬运"],"content":"概念: ​ 在web中的:(下面描述讲解的是web) ​ 幂等: ​ 对于同一种行为，如果执行不论多少次，最终的结果都是一致相同的，就称这种行为是幂等的。 ​ 非幂等: ​ 对于同一种行为，如果最终的结果与执行的次数有关，每次执行后结果都不相同，就称这种行为为非幂等。譬如：累加 ​ 在数学上的概念: ​ 这是个高等代数中的概念。简而言之就是x^Y=x x可能是任何元素，包括（数、矩阵等） 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果； 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱； 发送消息，也应该只发一次； 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题等等很多重要的情况都需要幂等的特性来支持。 ","date":"2023-11-21","objectID":"/7/:0:1","tags":["docker"],"title":"幂等和非幂等","uri":"/7/"},{"categories":["搬运"],"content":"实现: 可以通过http协议(超文本传输协议):来区分。get，put，delete是天然的幂等操作，所以在尽量使用这些方法。 建立唯一索引，能防止新增的脏数据，比如在银行的账户中，每个支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建银行账户多个，那么给账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录。要点：唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）。 token + (redis) 的机制(token的特点 : 一次有效性，时效性，可以对流量进行控制)，可以防止页面的重复提交。具体实现 : 发生的原因由于重复的点击 , 网络原因导致了多次发送请求，或者由于nginx重发等情况会导致数据被重复的提交 ; 解决的方案 : 在数据提交给后台服务器处理时，要向服务器申请token(全局唯一的变量)，将token存放到redis(可以是其他的)中，设置token的有效时间。 当服务器接受到请求进行处理时，对token进行校验，校验通过后并删除该token，并生成新的token返回 悲观锁和乐观锁：(详见) 悲观锁 : 更新数据时认为此次操作会造成数据的缺失。 注意 : id字段必须时主键或者唯一索引，不然的话就锁了整个表，导致效率降低，必须开启事务，缺点容易造成死锁，不建议使用 乐观锁 : 更新数据时认为此次操作不会造成数据缺失，所以只是在更新数据那一刻锁表，其他时间不锁表，相对于悲观锁的效率更高。 实现方式 : 在数据库的表中增加一个字段version(版本号)或者是其他的状态位。在对表进行操作时同时取出数据和标志位version，当要修改数据表时，对version进行判断是否与之前取出的一致，如果一致则修改，如果不一致则不修改。同时version自增一存入数据库。 (注意 : 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表) 分布式锁，加入系统部署在分布式系统上，构建全局的唯一索引比较困难(唯一的字段无法没法确定)，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供)； 状态机制，在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 ","date":"2023-11-21","objectID":"/7/:0:2","tags":["docker"],"title":"幂等和非幂等","uri":"/7/"},{"categories":["技术"],"content":" 功能测试文章 Lighthouse (image) images: [] tags: [] categories: [] featuredImage: \"\" featuredImagePreview: \"\" tags: 文章的标签. categories: 文章所属的类别. lightgallery: true $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\] \\begin{equation*} \\rho \\frac{\\mathrm{D} \\mathbf{v}}{\\mathrm{D} t}=\\nabla \\cdot \\mathbb{P}+\\rho \\mathbf{f} \\end{equation*} \\begin{equation} \\mathbf{E}=\\sum_{i} \\mathbf{E}_{i}=\\mathbf{E}_{1}+\\mathbf{E}_{2}+\\mathbf{E}_{3}+\\cdots \\end{equation} \\begin{align} a\u0026=b+c \\\\ d+e\u0026=f \\end{align} \\begin{alignat}{2} 10\u0026x+\u00263\u0026y = 2 \\\\ 3\u0026x+\u002613\u0026y = 4 \\end{alignat} \\begin{gather} a=b \\\\ e=b+c \\end{gather} \\begin{CD} A @\u003ea\u003e\u003e B \\\\ @VbVV @AAcA \\\\ C @= D \\end{CD} This is a tip 一个 技巧 横幅 或者 This is a tip 一个 技巧 横幅 ","date":"2023-11-21","objectID":"/first_post-%E5%89%AF%E6%9C%AC-10-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC/:0:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/first_post-%E5%89%AF%E6%9C%AC-10-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC/"},{"categories":["技术"],"content":" 功能测试文章 Lighthouse (image) images: [] tags: [] categories: [] featuredImage: \"\" featuredImagePreview: \"\" tags: 文章的标签. categories: 文章所属的类别. lightgallery: true $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\] \\begin{equation*} \\rho \\frac{\\mathrm{D} \\mathbf{v}}{\\mathrm{D} t}=\\nabla \\cdot \\mathbb{P}+\\rho \\mathbf{f} \\end{equation*} \\begin{equation} \\mathbf{E}=\\sum_{i} \\mathbf{E}_{i}=\\mathbf{E}_{1}+\\mathbf{E}_{2}+\\mathbf{E}_{3}+\\cdots \\end{equation} \\begin{align} a\u0026=b+c \\\\ d+e\u0026=f \\end{align} \\begin{alignat}{2} 10\u0026x+\u00263\u0026y = 2 \\\\ 3\u0026x+\u002613\u0026y = 4 \\end{alignat} \\begin{gather} a=b \\\\ e=b+c \\end{gather} \\begin{CD} A @\u003ea\u003e\u003e B \\\\ @VbVV @AAcA \\\\ C @= D \\end{CD} This is a tip 一个 技巧 横幅 或者 This is a tip 一个 技巧 横幅 ","date":"2023-11-21","objectID":"/first_post-%E5%89%AF%E6%9C%AC-11-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC/:0:0","tags":["响应式","编程"],"title":"自学响应式编程(一)","uri":"/first_post-%E5%89%AF%E6%9C%AC-11-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC-%E5%89%AF%E6%9C%AC/"},{"categories":["技术"],"content":" 线程同步可以说在日常开发中是用的很多， 但对于其内部如何实现的，一般人可能知道的并不多。介绍linux中的锁实现futex的优点及原理，最后分析java中同步机制如wait/notify, synchronized, ReentrantLock。 ","date":"2023-11-20","objectID":"/2/:0:0","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"自己实现锁 ","date":"2023-11-20","objectID":"/2/:1:0","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"自旋 volatile int status=0; void lock(){ while(!compareAndSet(0,1)){ } //get lock } void unlock(){ status=0; } boolean compareAndSet(int except,int newValue){ //cas操作,修改status成功则返回true } 上面的代码通过自旋和cas来实现一个最简单的锁。 这样实现的锁显然有个致命的缺点：耗费cpu资源。没有竞争到锁的线程会一直占用cpu资源进行cas操作，假如一个线程获得锁后要花费10s处理业务逻辑，那另外一个线程就会白白的花费10s的cpu资源。（假设系统中就只有这两个线程的情况）。 ","date":"2023-11-20","objectID":"/2/:1:1","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"yield+自旋 要解决自旋锁的性能问题必须让竞争锁失败的线程不忙等,而是在获取不到锁的时候能把cpu资源给让出来，说到让cpu资源，你可能想到了yield()方法，看看下面的例子： volatile int status=0; void lock(){ while(!compareAndSet(0,1)){ yield(); } //get lock } void unlock(){ status=0; } 当线程竞争锁失败时，会调用yield方法让出cpu。需要注意的是该方法只是当前让出cpu，有可能操作系统下次还是选择运行该线程。其实现是 将当期线程移动到所在优先调度队列的末端（操作系统线程调度了解一下？有时间的话，下次写写这块内容）。也就是说，如果该线程处于优先级最高的调度队列且该队列只有该线程，那操作系统下次还是运行该线程。 自旋+yield的方式并没有完全解决问题，当系统只有两个线程竞争锁时，yield是有效的。但是如果有100个线程竞争锁，当线程1获得锁后，还有99个线程在反复的自旋+yield，线程2调用yield后，操作系统下次运行的可能是线程3；而线程3CAS失败后调用yield后，操作系统下次运行的可能是线程4… 假如运行在单核cpu下，在竞争锁时最差只有1%的cpu利用率，导致获得锁的线程1一直被中断，执行实际业务代码时间变得更长，从而导致锁释放的时间变的更长。 ","date":"2023-11-20","objectID":"/2/:1:2","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"sleep+自旋 当竞争锁失败后，可以将用Thread.sleep将线程休眠，从而不占用cpu资源： volatile int status=0; void lock(){ while(!compareAndSet(0,1)){ sleep(10); } //get lock } void unlock(){ status=0; } 上述方式我们可能见的比较多，通常用于实现上层锁。该方式不适合用于操作系统级别的锁，因为作为一个底层锁，其sleep时间很难设置。sleep的时间取决于同步代码块的执行时间，sleep时间如果太短了，会导致线程切换频繁（极端情况和yield方式一样）；sleep时间如果设置的过长，会导致线程不能及时获得锁。因此没法设置一个通用的sleep值。就算sleep的值由调用者指定也不能完全解决问题：有的时候调用锁的人也不知道同步块代码会执行多久。 ","date":"2023-11-20","objectID":"/2/:1:3","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"park+自旋 那可不可以在获取不到锁的时候让线程释放cpu资源进行等待，当持有锁的线程释放锁的时候将等待的线程唤起呢？ volatile int status=0; Queue parkQueue; void lock(){ while(!compareAndSet(0,1)){ // lock_wait(); } //get lock } void synchronized unlock(){ lock_notify(); } void lock_wait(){ //将当期线程加入到等待队列 parkQueue.add(nowThread); //将当期线程释放cpu releaseCpu(); } void lock_notify(){ //得到要唤醒的线程 Thread t=parkList.poll(); //唤醒等待线程 wakeAThread(t); } 上面是伪代码，描述这种设计思想，至于释放cpu资源、唤醒等待线程的的具体实现 ","date":"2023-11-20","objectID":"/2/:1:4","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"小结 对于锁冲突不严重的情况，用自旋锁会更适合，试想每个线程获得锁后很短的一段时间内就释放锁，竞争锁的线程只要经历几次自旋运算后就能获得锁，那就没必要等待该线程了，因为等待线程意味着需要进入到内核态进行上下文切换，而上下文切换是有成本的并且还不低，如果锁很快就释放了，那上下文切换的开销将超过自旋。 目前操作系统中，一般是用自旋+等待结合的形式实现锁：在进入锁时先自旋一定次数，如果还没获得锁再进行等待。 ","date":"2023-11-20","objectID":"/2/:1:5","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"futex linux底层用futex实现锁，futex由一个内核层的队列和一个用户空间层的atomic integer构成。当获得锁时，尝试cas更改integer，如果integer原始值是0，则修改成功，该线程获得锁，否则就将当期线程放入到 wait queue中（即操作系统的等待队列）。 上述说法有些抽象，如果你没看明白也没关系。我们先看一下没有futex之前，linux是怎么实现锁的。 ","date":"2023-11-20","objectID":"/2/:2:0","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"futex诞生之前 在futex诞生之前，linux下的同步机制可以归为两类：用户态的同步机制 和内核同步机制。 用户态的同步机制基本上就是利用原子指令实现的自旋锁。关于自旋锁其缺点也说过了，不适用于大的临界区（即锁占用时间比较长的情况）。 内核提供的同步机制，如semaphore等，使用的是上文说的自旋+等待的形式。 它对于大小临界区和都适用。但是因为它是内核层的（释放cpu资源是内核级调用），所以每次lock与unlock都是一次系统调用，即使没有锁冲突，也必须要通过系统调用进入内核之后才能识别。 理想的同步机制应该是没有锁冲突时在用户态利用原子指令就解决问题，而需要挂起等待时再使用内核提供的系统调用进行睡眠与唤醒。换句话说，在用户态的自旋失败时，能不能让进程挂起，由持有锁的线程释放锁时将其唤醒？ 如果你没有较深入地考虑过这个问题，很可能想当然的认为类似于这样就行了（伪代码）： void lock(int lockval) { //trylock是用户级的自旋锁 while(!trylock(lockval)) { wait();//释放cpu，并将当期线程加入等待队列，是系统调用 } } boolean trylock(int lockval){ int i=0; //localval=1代表上锁成功 while(!compareAndSet(lockval,0,1)){ if(++i\u003e10){ return false; } } return true; } void unlock(int lockval) { compareAndSet(lockval,1,0); notify(); } 上述代码的问题是trylock和wait两个调用之间存在一个窗口： 如果一个线程trylock失败，在调用wait时持有锁的线程释放了锁，当前线程还是会调用wait进行等待，但之后就没有人再将该线程唤醒了。 ","date":"2023-11-20","objectID":"/2/:2:1","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":"futex诞生之后 我们来看看futex的方法定义： //uaddr指向一个地址，val代表这个地址期待的值，当*uaddr==val时，才会进行wait int futex_wait(int *uaddr, int val); //唤醒n个在uaddr指向的锁变量上挂起等待的进程 int futex_wake(int *uaddr, int n); futex_wait真正将进程挂起之前会检查addr指向的地址的值是否等于val，如果不相等则会立即返回，由用户态继续trylock。否则将当期线程插入到一个队列中去，并挂起。 futex内部维护了一个队列，在线程挂起前会线程插入到其中，同时对于队列中的每个节点都有一个标识，代表该线程关联锁的uaddr。这样，当用户态调用futex_wake时，只需要遍历这个等待队列，把带有相同uaddr的节点所对应的进程唤醒就行了。 作为优化，futex维护的其实是个类似java 中的concurrent hashmap的结构。其持有一个总链表，总链表中每个元素都是一个带有自旋锁的子链表。调用futex_wait挂起的进程，通过其uaddr hash到某一个具体的子链表上去。这样一方面能分散对等待队列的竞争、另一方面减小单个队列的长度，便于futex_wake时的查找。每个链表各自持有一把spinlock，将\"*uaddr和val的比较操作\"与\"把进程加入队列的操作\"保护在一个临界区中。 另外，futex是支持多进程的，当使用futex在多进程间进行同步时，需要考虑同一个物理内存地址在不同进程中的虚拟地址是不同的。 ","date":"2023-11-20","objectID":"/2/:2:2","tags":["多线程","线程安全"],"title":"线程同步...","uri":"/2/"},{"categories":["技术"],"content":" 平常函数式组件用的多一点,React Hooks 是 React 团队在两年前的 16.8 版本推出的一套全新的机制,它可以让你在不编写 class 的情况下使用 state 以及其他的 React 特性。 ","date":"2023-11-19","objectID":"/3/:0:0","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"几个内置Hooks的作用以及使用 ","date":"2023-11-19","objectID":"/3/:1:0","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"useState ：让函数组件具有维持状态的能力 const[count, setCount]=useState(0); 优点： 让函数组件具有维持状态的能力，即：在一个函数组件的多次渲染之间，这个 state 是共享的。便于维护状态。 ","date":"2023-11-19","objectID":"/3/:1:1","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"缺点： 一旦组件有自己状态，意味着组件如果重新创建，就需要有恢复状态的过程，这通常会让组件变得更复杂。 用法： useState(initialState) 的参数 initialState 是创建 state 的初始值。 它可以是任意类型，比如数字、对象、数组等等。 useState() 的返回值是一个有着两个元素的数组。第一个数组元素用来读取 state 的值，第二个则是用来设置这个 state 的值。 在这里要注意的是，state 的变量（例子中的 count）是只读的，所以我们必须通过第二个数组元素 setCount 来设置它的值。 如果要创建多个 state ，那么我们就需要多次调用 useState。 什么样的值应该保存在 state 中？ 通常来说，我们要遵循的一个原则就是：state 中不要保存可以通过计算得到的值 。 从 props 传递过来的值。有时候 props 传递过来的值无法直接使用，而是要通过一定的计算后再在 UI 上展示，比如说排序。那么我们要做的就是每次用的时候，都重新排序一下，或者利用某些 cache 机制，而不是将结果直接放到 state 里。 从 URL 中读到的值。比如有时需要读取 URL 中的参数，把它作为组件的一部分状态。那么我们可以在每次需要用的时候从 URL 中读取，而不是读出来直接放到 state 里。 从 cookie、localStorage 中读取的值。通常来说，也是每次要用的时候直接去读取，而不是读出来后放到 state 里。 useEffect：执行副作用 useEffect(fn, deps); useEffect ，顾名思义，用于执行一段副作用。 ","date":"2023-11-19","objectID":"/3/:1:2","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"什么是副作用？ 通常来说，副作用是指一段和当前执行结果无关的代码。比如说要修改函数外部的某个变量，要发起一个请求，等等。 也就是说，在函数组件的当次执行过程中， useEffect 中代码的执行是不影响渲染出来的 UI 的。 对应到 Class 组件，那么 useEffect 就涵盖了 ComponentDidMount、componentDidUpdate 和 componentWillUnmount 三个生命周期方法。不过如果你习惯了使用 Class 组件，那千万不要按照把 useEffect 对应到某个或者某几个生命周期的方法。你只要记住，useEffect 是每次组件 render 完后判断依赖并执行就可以了。 useEffect 还有两个特殊的用法：没有依赖项，以及依赖项作为空数组。我们来具体分析下。 没有依赖项，则每次 render 后都会重新执行。例如： javascript 复制代码useEffect(() =\u003e { // 每次 render 完一定执行 console.log('渲染...........'); }); 空数组作为依赖项，则只在首次执行时触发，对应到 Class 组件就是 componentDidMount。例如： scss 复制代码useEffect(() =\u003e { // 组件首次渲染时执行，等价于 class 组件中的 componentDidMount console.log('did mount........'); }, []); ","date":"2023-11-19","objectID":"/3/:1:3","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"小结用法: 总结一下，useEffect 让我们能够在下面四种时机去执行一个回调函数产生副作用： 每次 render 后执行：不提供第二个依赖项参数。 比如useEffect(() =\u003e {})。 仅第一次 render 后执行：提供一个空数组作为依赖项。 比如useEffect(() =\u003e {}, [])。 第一次以及依赖项发生变化后执行：提供依赖项数组。 比如useEffect(() =\u003e {}, [deps])。 组件 unmount 后执行：返回一个回调函数。 比如useEffect() =\u003e { return () =\u003e {} }, [])。 useCallback：缓存回调函数 useCallback(fn, deps) ","date":"2023-11-19","objectID":"/3/:1:4","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"为什么要使用useCallback? 在 React 函数组件中， 每一次 UI 的变化，都是通过重新执行整个函数来完成的 ，这和传统的 Class 组件有很大区别：函数组件中并没有一个直接的方式在多次渲染之间维持一个状态。 javascript 复制代码function Counter() { const [count, setCount] = useState(0); const handleIncrement = () =\u003e setCount(count+1); return \u003cbutton onClick={handleIncrement}\u003e+\u003c/button\u003e } 思考下这个过程。 每次组件状态发生变化的时候，函数组件实际上都会重新执行一遍 。在每次执行的时候，实际上都会创建一个新的事件处理函数 handleIncrement 。 这也意味着，即使 count 没有发生变化，但是函数组件因为其它状态发生变化而重新渲染时（函数组件重新被执行），这种写法也会每次创建一个新的函数。创建一个新的事件处理函数，虽然不影响结果的正确性，但其实是没必要的。因为这样做不仅增加了系统的开销，更重要的是： 每次创建新函数的方式会让接收事件处理函数的组件，需要重新渲染 。 比如这个例子中的 button 组件，接收了 handleIncrement ，并作为一个属性。如果每次都是一个新的，那么这个 React 就会认为这个组件的 props 发生了变化，从而必须重新渲染。因此，我们需要做到的是： 只有当 count 发生变化时，我们才需要重新定一个回调函数 。而这正是 useCallback 这个 Hook 的作用。 javascript 复制代码import React, { useState, useCallback } from 'react'; function Counter() { const [count, setCount] = useState(0); const handleIncrement = useCallback( () =\u003e setCount(count + 1), [count], // 只有当 count 发生变化时，才会重新创建回调函数 ); return \u003cbutton onClick={handleIncrement}\u003e+\u003c/button\u003e } useMemo：缓存计算的结果 js 复制代码useMemo(fn, deps); useCallback(fn, deps) 相当于 useMemo(() =\u003e fn, deps)。 这里的 fn 是产生所需数据的一个 计算函数 。通常来说， fn 会使用 deps 中声明的一些变量来生成一个结果，用来渲染出最终的 UI 。 这个场景应该很容易理解：如果某个 数据 是通过其它数据计算得到的，那么只有当用到的数据，也就是依赖的数据发生变化的时候，才应该需要重新计算。 ","date":"2023-11-19","objectID":"/3/:1:5","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"避免重复计算 通过 useMemo 这个 Hook，可以避免在用到的数据没发生变化时进行的重复计算。虽然例子展示的是一个很简单的场景，但如果是一个复杂的计算，那么对于 提升性能 会有很大的帮助。 举个例子： css 复制代码const calc = (a, b) =\u003e { // 假设这里做了复杂的计算，暂时用次幂模拟 return a ** b; } const MyComponent = (props) =\u003e { const {a, b} = props; const c = calc(a, b); return \u003cdiv\u003ec: {c}\u003c/div\u003e; } 如果 calc 计算耗时 1000ms，那么每次渲染都要等待这么久，怎么优化呢？ a, b 值不变的情况下，得出的 c 定是相同的。 所以我们可以用 useMemo 把值给缓存起来，避免重复计算相同的结果。 javascript 复制代码const calc = (a, b) =\u003e { // 假设这里做了复杂的计算，暂时用次幂模拟 return a ** b; } const MyComponent = (props) =\u003e { const {a, b} = props; // 缓存 const c = React.useMemo(() =\u003e calc(a, b), [a, b]); return \u003cdiv\u003ec: {c}\u003c/div\u003e; } useCallback 的功能其实是可以用 useMemo 来实现的: javascript 复制代码 const myEventHandler = useMemo(() =\u003e { // 返回一个函数作为缓存结果 return () =\u003e { // 在这里进行事件处理 } }, [dep1, dep2]); ","date":"2023-11-19","objectID":"/3/:1:6","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"小结一下： 感觉到这有这种感觉，其实 hook 就是建立了一个绑定某个结果到依赖数据的关系。只有当依赖变了，这个结果才需要被重新得到。 useRef：在多次渲染之间共享数据 ini 复制代码const myRefContainer =useRef(initialValue); 我们可以把 useRef 看作是在函数组件之外创建的一个容器空间。在这个容器上，我们可以通过唯一的 current 属设置一个值，从而在函数组件的多次渲染之间共享这个值。 ","date":"2023-11-19","objectID":"/3/:1:7","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"useRef 的重要的功能 1. 存储跨渲染的数据 使用 useRef 保存的数据一般是和 UI 的渲染无关的，因此当 ref 的值发生变化时，是不会触发组件的重新渲染的，这也是 useRef 区别于 useState 的地方。 举例： scss 复制代码 const [time, setTime] = useState(0); // 定义 timer 这样一个容器用于在跨组件渲染之间保存一个变量 const timer = useRef(null); const handleStart = useCallback(() =\u003e { // 使用 current 属性设置 ref 的值 timer.current = window.setInterval(() =\u003e { setTime((time) =\u003e time + 1); }, 100); }, []); 2. 保存某个 DOM 节点的引用 是在某些场景中，我们必须要获得真实 DOM 节点的引用，所以结合 React 的 ref 属性和 useRef 这个 Hook，我们就可以获得真实的 DOM 节点，并对这个节点进行操作。 React 官方例子： javascript 复制代码function TextInputWithFocusButton() { const inputEl = useRef(null); const onButtonClick = () =\u003e { // current 属性指向了真实的 input 这个 DOM 节点，从而可以调用 focus 方法 inputEl.current.focus(); }; return ( \u003c\u003e \u003cinput ref={inputEl} type=\"text\" /\u003e \u003cbutton onClick={onButtonClick}\u003eFocus the input\u003c/button\u003e \u003c/\u003e ); } 理解： 可以看到ref 这个属性提供了获得 DOM 节点的能力，并利用 useRef 保存了这个节点的应用。这样的话，一旦 input 节点被渲染到界面上，那我们通过 inputEl.current 就能访问到真实的 DOM 节点的实例了 ","date":"2023-11-19","objectID":"/3/:1:8","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"useContext：定义全局状态 ","date":"2023-11-19","objectID":"/3/:1:9","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"为什么要使用 useContext？ React 组件之间的状态传递只有一种方式，那就是通过 props。缺点： 这种传递关系只能在父子组件之间进行。 那么问题出现：跨层次，或者同层的组件之间要如何进行数据的共享？这就涉及到一个新的命题： 全局状态管理 。 react提供的解决方案： Context 机制。 ","date":"2023-11-19","objectID":"/3/:1:10","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"具体原理： React 提供了 Context 这样一个机制， 能够让所有在某个组件开始的组件树上创建一个 Context 。这样这个组件树上的所有组件，就都能访问和修改这个 Context 了。 那么在函数组件里，我们就可以使用 useContext 这样一个 Hook 来管理 Context。 ","date":"2023-11-19","objectID":"/3/:1:11","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"使用：（这儿用了官方例子） javascript 复制代码const themes = { light: { foreground: \"#000000\", background: \"#eeeeee\" }, dark: { foreground: \"#ffffff\", background: \"#222222\" } }; // 创建一个 Theme 的 Context const ThemeContext = React.createContext(themes.light); function App() { // 整个应用使用 ThemeContext.Provider 作为根组件 return ( // 使用 themes.dark 作为当前 Context \u003cThemeContext.Provider value={themes.dark}\u003e \u003cToolbar /\u003e \u003c/ThemeContext.Provider\u003e ); } // 在 Toolbar 组件中使用一个会使用 Theme 的 Button function Toolbar(props) { return ( \u003cdiv\u003e \u003cThemedButton /\u003e \u003c/div\u003e ); } // 在 Theme Button 中使用 useContext 来获取当前的主题 function ThemedButton() { const theme = useContext(ThemeContext); return ( \u003cbutton style={{ background: theme.background, color: theme.foreground }}\u003e I am styled by theme context! \u003c/button\u003e ); } ","date":"2023-11-19","objectID":"/3/:1:12","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"优点： Context 提供了一个方便在多个组件之间共享数据的机制。 ","date":"2023-11-19","objectID":"/3/:1:13","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"缺点： Context 相当于提供了一个定义 React 世界中全局变量的机制，而全局变量则意味着两点： 1. 会让调试变得困难，因为你很难跟踪某个 Context 的变化究竟是如何产生的。 2. 让组件的复用变得困难，因为一个组件如果使用了某个 Context ，它就必须确保被用到的地方一定有这个 Context 的 Provider 在其父组件的路径上。 实际应用场景 由于以上缺点，所以在 React 的开发中，除了像 Theme、Language 等一目了然的需要全局设置的变量外），我们很少会使用 Context 来做太多数据的共享。需要再三强调的是，Context 更多的是提供了一个强大的机制，让 React 应用具备定义全局的响应式数据的能力。 此外，很多状态管理框架，比如 Redux，正是利用了 Context 的机制来提供一种更加可控的组件之间的状态管理机制。因此，理解 Context 的机制，也可以让我们更好地去理解 Redux 这样的框架实现的原理。 ","date":"2023-11-19","objectID":"/3/:1:14","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"最后 其实了解学会了useState 和 useEffect 这两个 核心 Hooks，基本能完成绝大多数 React 功能的开发了。 useCallback、useMemo、useRef 和 useContext。这几个 Hook 都是为了解决函数组件中遇到的特定问题。 ","date":"2023-11-19","objectID":"/3/:1:15","tags":["react","钩子函数"],"title":"React钩子","uri":"/3/"},{"categories":["技术"],"content":"SpringBoot集成flyway 在 pom.xml 加入如下依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.flywaydb\u003c/groupId\u003e \u003cartifactId\u003eflyway-core\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.flywaydb\u003c/groupId\u003e \u003cartifactId\u003eflyway-mysql\u003c/artifactId\u003e \u003c/dependency\u003e 在application.yml中加入配置 flyway: #是否开启flyway，默认true enabled: false #当迁移时发现目标schema非空，而且没有元数据的表时，（即迭代中项目）是否自动执行基准迁移，默认false. baseline-on-migrate: true # 是否允许无序运行迁移, 默认false，建议开发环境开启，生成环境关闭 out-of-order: true #设定SQL脚本的目录,可以配置多个，比如为classpath:db/migration,filesystem:/sql-migrations,默认classpath:db/migration locations: - classpath:db/migration sql文件命名规范 Prefix 前缀：V 代表版本迁移，U 代表撤销迁移，R 代表可重复迁移 Version 版本号：版本号通常 . 和整数组成 Separator 分隔符：固定由两个下划线 __ 组成 Description 描述：由下划线分隔的单词组成，用于描述本次迁移的目的 Suffix 后缀：如果是 SQL 文件那么固定由 .sql 组成，如果是基于 Java 类则默认不需要后缀 例如V1.0__init_db.sql 执行了 V1.0__init_db.sql 脚本后，从而创建了 user 表，另外还自动创建了 flyway_schema_history 表，用于记录所有版本演化和状态，其表结构如下(以 MySQL 为例)： 注意 org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Migration checksum mismatch for migration version 1.0 -\u003e Applied to database : 1317299633 -\u003e Resolved locally : -1582367361 这个错误的原因就是 Flyway 会给脚本计算一个 checksum 保存在数据库中，用于在之后运行过程中对比 sql 文件是否有变化，如果发生了变化，则会报错，也就防止了误修改脚本导致发生问题。 ","date":"2023-11-18","objectID":"/4/:0:1","tags":["SpringBoot","java"],"title":"SpringBoot集成flyway","uri":"/4/"}]